from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit
from pyspark.ml.feature import StringIndexer
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np


# Avvia Spark
spark = (SparkSession.builder
         .appName("InSDN Optimized")
         .getOrCreate())

# Carica il dataset
input_directory = "/home/ilaria/Scaricati/InSDN_DatasetCSV"
data = spark.read.csv(input_directory, header=True, inferSchema=True)
data.show()

# Seleziona solo le colonne più utili
selected_columns = [
    "Flow Duration", "Tot Fwd Pkts", "Tot Bwd Pkts",
    "Fwd Pkt Len Mean", "Bwd Pkt Len Mean", "Flow Byts/s", "Label"
]
data = data.select(selected_columns)

# Converte la colonna "Label" in numerico
indexer = StringIndexer(inputCol="Label", outputCol="label_indexed")
data = indexer.fit(data).transform(data)

# Mostra le etichette distinte
print("Label")
data.groupBy("Label", "label_indexed").count().orderBy("Label").show()

# Pre-elaborazione delle feature
features = [col for col in data.columns if col != "Label" and col != "label_indexed"]
assembler = VectorAssembler(inputCols=features, outputCol="featuresAssembled") # aggrega le feature numeriche in un unico vettore
scaler = StandardScaler(inputCol="featuresAssembled", outputCol="features_standard") # normalizza i dati

# Testa il VectorAssembler
assembled_data = assembler.transform(data)
assembled_data.show(5)

# Testa il StandardScaler
scaled_data = scaler.fit(assembled_data).transform(assembled_data)
scaled_data.show(5)

## RandomForestClassifier: Modello basato su struttura con più alberi decisionali indipendeti
rf = RandomForestClassifier(featuresCol="features_standard", labelCol="label_indexed")
rf_pipeline = Pipeline(stages=[assembler, scaler, rf])

## Validazione dei modelli utile per selezionare i modelli/paramentri ottimali
# TrainValidationSplit esegue una suddivisione dei dati in training e test utilizzando il trainRatio
# Imposta la Train-Validation Split per ottimizzare i modelli
paramGrid_rf = ParamGridBuilder().addGrid(rf.numTrees, [10, 50]).build() # costruisce una griglia di parametri
tvs_rf = TrainValidationSplit(
    estimator=rf_pipeline, # pipeline da ottimizzare
    estimatorParamMaps=paramGrid_rf,
    # evaluator {RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator}
    evaluator=MulticlassClassificationEvaluator(labelCol="label_indexed", predictionCol="prediction", metricName="accuracy"), # metrica per valutare le prestazioni
    trainRatio=0.8
)

# Addestra i modelli

# Dividi il dataset in training e test
train, test = data.randomSplit([0.8, 0.2], seed=42)
print(f"Training set count: {train.count()}, Test set count: {test.count()}")

rf_model = tvs_rf.fit(train)

# Effettua predizioni
print("Random Forest")
rf_predictions = rf_model.transform(test) # transform() trasforma il DataFrame in un altro aggiungendo nuove colonne, in questo caso viene aggiunta la colonna della predezione
rf_predictions.show(10)
#print("Quante volte viene predetta la classe")
#rf_predictions.groupBy("label_indexed", "prediction").count().show()
print("Conteggio tra classi reali e predette")
rf_predictions.groupBy("Label", "label_indexed", "prediction").count().orderBy("Label").show()

evaluator = MulticlassClassificationEvaluator(labelCol="label_indexed", predictionCol="prediction", metricName="accuracy") # valuta le prestazioni
rf_accuracy = evaluator.evaluate(rf_predictions)
print("Random Forest Accuracy:", rf_accuracy)

# Creazione della matrice di confusione
rf_predictions_pandas = rf_predictions.toPandas()
print("Predictions Pandas")
print(rf_predictions_pandas)
conf_matrix_rf = confusion_matrix(rf_predictions_pandas["label_indexed"],rf_predictions_pandas["prediction"])
print("Confusion Matrix")
print(conf_matrix_rf)

# Numero di classi
num_classes = conf_matrix_rf.shape[0]

# Per ogni classe, estrai i TP, FP, FN, TN
for i in range(num_classes):
    TP = conf_matrix_rf[i, i]  # True Positives
    FP = np.sum(conf_matrix_rf[:, i]) - TP  # False Positives (somma della colonna - TP)
    FN = np.sum(conf_matrix_rf[i, :]) - TP  # False Negatives (somma della riga - TP)
    TN = np.sum(conf_matrix_rf) - (TP + FP + FN)  # True Negatives (totale - TP - FP - FN)

    # Calcolo delle metriche
    precision = TP / (TP + FP) if (TP + FP) != 0 else 0
    recall = TP / (TP + FN) if (TP + FN) != 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0

    print(f"Class {i}:")
    print(f"  TP = {TP}, FP = {FP}, FN = {FN}, TN = {TN}")
    print(f"  Precision = {precision:.4f}")
    print(f"  Recall = {recall:.4f}")
    print(f"  F1-Score = {f1_score:.4f}")
    print("---------------------------")

# Arresta Spark
spark.stop()
